"""
Specific test for the "Total Rows in **Methodology**" chart issue.
This test replicates the exact problem the user reported and verifies it's fixed.
"""

import sys
import os
from chart_renderer import ChartRenderer

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


def test_methodology_table_fix():
    """Test the specific case that was generating 'Total Rows in **Methodology**' charts."""  # noqa: E501
    print("=== Testing Methodology Table Fix ===")
    print("Replicating the exact issue reported by the user...\n")

    # This is the type of table that was causing the problem
    # A complex methodology comparison table with mostly text data
    methodology_table = """| Methodology | Approach | Effectiveness | Implementation Difficulty | Best Use Cases |  # noqa: E501
| --- | --- | --- | --- | --- |
| Agile | Iterative development | High | Medium | Complex projects |
| Waterfall | Sequential phases | Medium | Low | Well-defined requirements |
| DevOps | Continuous integration | High | High | Modern software delivery |
| Lean | Waste elimination | Medium | Medium | Process optimization |"""

    renderer = ChartRenderer()

    # Parse the table
    print("1. Parsing methodology table...")
    table_data = renderer._parse_markdown_table(methodology_table)

    if not table_data:
        print("   ‚úó FAILED to parse table")
        return False

    print(
        f"   ‚úì Parsed successfully: {len(table_data['headers'])} columns, {len(table_data['rows'])} rows"  # noqa: E501
    )
    print(f"   Headers: {table_data['headers']}")

    # Infer chart type
    print("\n2. Inferring chart type...")
    chart_type = renderer._infer_chart_type(table_data)
    print(f"   Chart type determined: {chart_type}")

    # Generate chart URL
    print("\n3. Generating chart...")
    chart_url = renderer._generate_quickchart_url(table_data, chart_type)

    if chart_url is None:
        print("   ‚úì EXCELLENT: No chart generated (better than meaningless chart)")
        print("   This prevents the 'Total Rows in **Methodology**' problem!")
        return True

    print(f"   Chart URL generated: {len(chart_url)} characters")

    # Check if it's the problematic fallback chart
    # The old system would create a chart with "Total Rows in Methodology" and value 4
    if "Total Rows" in chart_url and "Methodology" in chart_url:
        print("   ‚úó FAILED: Still generating the problematic 'Total Rows' chart")
        print("   This is exactly what the user reported as broken!")
        return False

    # Check if the chart contains actual data from the table
    methodology_names = ["Agile", "Waterfall", "DevOps", "Lean"]
    chart_contains_real_data = any(name in chart_url for name in methodology_names)

    if chart_contains_real_data:
        print("   ‚úì EXCELLENT: Chart contains actual methodology names!")
        print("   Chart now uses real data instead of generic row counts.")
        return True

    # Even if it doesn't contain the exact names, as long as it's not the fallback, it's better  # noqa: E501
    print("   ‚úì GOOD: Chart generated without the problematic fallback")
    print("   No longer shows 'Total Rows in **Methodology**'")
    return True


def test_specific_user_scenario():
    """Test the complete scenario as the user would experience it."""
    print("\n=== Testing Complete User Scenario ===")
    print("Simulating a user asking for methodology comparison...\n")

    # Simulate an LLM response that includes the problematic table
    llm_response = """Based on your request for methodology comparison, here's my analysis:  # noqa: E501

Different software development methodologies have varying approaches and effectiveness:

| Methodology | Approach | Effectiveness | Implementation | Notes |
| --- | --- | --- | --- | --- |
| Agile | Iterative | High | Medium | Great for changing requirements |
| Waterfall | Sequential | Medium | Low | Good for stable requirements |
| DevOps | Continuous | High | High | Requires cultural change |
| Lean | Waste reduction | Medium | Medium | Focus on efficiency |

Each methodology has its strengths and should be chosen based on project context."""

    renderer = ChartRenderer()

    print("1. Processing LLM response with methodology table...")
    cleaned_content, chart_data_list = renderer.extract_tables_for_rendering(
        llm_response
    )

    print(f"   Original response: {len(llm_response)} characters")
    print(f"   Cleaned content: {len(cleaned_content)} characters")
    print(f"   Charts found: {len(chart_data_list)}")

    if len(chart_data_list) == 0:
        print("   ‚úì ACCEPTABLE: No charts generated (avoids meaningless charts)")
        return True

    # Check each generated chart
    for i, chart_data in enumerate(chart_data_list, 1):
        print(f"\n2. Analyzing Chart {i}...")
        chart_url = chart_data.get("url", "")
        chart_type = chart_data.get("type", "unknown")

        print(f"   Type: {chart_type}")
        print(f"   Placeholder: {chart_data.get('placeholder', 'N/A')}")

        # The critical test: make sure it's NOT the problematic chart
        if "Total Rows" in chart_url and "Methodology" in chart_url:
            print(
                "   ‚úó CRITICAL FAILURE: Generated 'Total Rows in **Methodology**' chart!"  # noqa: E501
            )
            print("   This is exactly the bug the user reported!")
            return False

        if chart_url:
            print("   ‚úì Chart generated successfully")

            # Check if it uses real data
            methodology_terms = [
                "Agile",
                "Waterfall",
                "DevOps",
                "Lean",
                "Iterative",
                "Sequential",
            ]
            if any(term in chart_url for term in methodology_terms):
                print("   ‚úì EXCELLENT: Chart uses actual methodology data!")
            else:
                print("   ‚úì GOOD: Chart generated without problematic fallback")
        else:
            print("   ‚úó No chart URL generated")

    print("\n‚úì SUCCESS: No 'Total Rows in **Methodology**' charts generated!")
    return True


def test_edge_cases():
    """Test edge cases that might trigger the old problematic behavior."""
    print("\n=== Testing Edge Cases ===")

    renderer = ChartRenderer()

    edge_cases = [
        # All text data
        (
            "All Text Table",
            """| Category | Description | Notes |
| --- | --- | --- |
| Design | User interface | Important |
| Backend | Server logic | Complex |
| Testing | Quality assurance | Critical |""",
        ),
        # Mixed qualitative data
        (
            "Qualitative Data",
            """| Feature | Priority | Status | Complexity |
| --- | --- | --- | --- |
| Login | High | Done | Low |
| Dashboard | Medium | In Progress | High |
| Reports | Low | Planned | Medium |""",
        ),
        # Very wide table
        (
            "Wide Table",
            """| A | B | C | D | E | F | G | H |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 1 | Data | More | Info | Details | Extra | Additional | Final |
| 2 | Text | Content | Material | Data | Information | Content | End |""",
        ),
    ]

    success_count = 0

    for case_name, table_text in edge_cases:
        print(f"\nTesting {case_name}...")

        table_data = renderer._parse_markdown_table(table_text)
        if not table_data:
            print(f"   ‚úó Failed to parse {case_name}")
            continue

        chart_type = renderer._infer_chart_type(table_data)
        chart_url = renderer._generate_quickchart_url(table_data, chart_type)

        # Check for the problematic pattern
        if chart_url and "Total Rows" in chart_url:
            print(f"   ‚úó {case_name}: Still generating 'Total Rows' fallback")
        else:
            print(f"   ‚úì {case_name}: No problematic fallback generated")
            success_count += 1

    print(f"\nEdge cases passed: {success_count}/{len(edge_cases)}")
    return success_count == len(edge_cases)


def main():
    """Run all tests for the methodology chart fix."""
    print("METHODOLOGY CHART FIX VERIFICATION")
    print("=" * 50)
    print("Testing fix for 'Total Rows in **Methodology**' issue")
    print("User reported charts showing meaningless row counts instead of data\n")

    tests = [
        ("Methodology Table Fix", test_methodology_table_fix),
        ("Complete User Scenario", test_specific_user_scenario),
        ("Edge Cases", test_edge_cases),
    ]

    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"\n‚úó ERROR in {test_name}: {e}")
            results.append((test_name, False))

    # Summary
    print("\n" + "=" * 50)
    print("FINAL RESULTS")
    print("=" * 50)

    passed = sum(1 for _, result in results if result)

    for test_name, result in results:
        status = "‚úì PASS" if result else "‚úó FAIL"
        print(f"{test_name}: {status}")

    print(f"\nOverall: {passed}/{len(results)} tests passed")

    if passed == len(results):
        print("\nüéâ ISSUE COMPLETELY FIXED!")
        print("‚úì No more 'Total Rows in **Methodology**' charts")
        print("‚úì Charts now use actual table data")
        print("‚úì Meaningless fallbacks eliminated")
        print("\nUsers will now see meaningful charts with real data!")
    elif passed >= len(results) * 0.67:
        print("\n‚úÖ MOSTLY FIXED!")
        print("The main issue is resolved, minor edge cases may remain.")
    else:
        print("\n‚ùå ISSUE NOT FULLY RESOLVED!")
        print("The problematic chart generation may still occur.")

    return passed == len(results)


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
